{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = open('./All_in_one.md', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = readme.split('\\n##')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Arabic NLP Survey Papers Repository (ASPR) - مستودع الأوراق المسحية في معالجة اللغة العربية (أسبر)\n",
      "\n",
      " General\n",
      " Enabling Tools (Morphology, Diacritization, Grammer, etc.)\n",
      " Text Classification & Mining\n",
      " Named Entity Recognition\n",
      " Quesion Answering\n",
      " Sentiment Analysis\n",
      " Speech\n",
      " Summarization\n",
      " Conversational AI (Chatbots & Dialogue systems)\n",
      " Word Sense Disambiguation (WSD)\n",
      " Dialects\n",
      " Plagiarism Detection Systems\n",
      " Machine Translation\n",
      " Handwriting Recognition & OCR\n",
      " Offensive Language Detection\n",
      " Fake news and Spam\n",
      " Ontology and Resources\n",
      " Information Retrieval\n",
      " Opinion Mining\n",
      " Knowledge Graph \n",
      " Query Expansion\n",
      " Religious Text\n",
      " Others (Steganography, Transfer Learning, Deep learning, etc.) \n"
     ]
    }
   ],
   "source": [
    "for part in parts:\n",
    "    print(part.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, len(parts)):\n",
    "    part = parts[i]\n",
    "    title = parts[i].split('\\n')[0].strip().replace(' ', '-')\n",
    "    home_link = \"[Table of Contents](README.md)\\n\\n\"\n",
    "    part = home_link + \"#\" + part \n",
    "    filename = str(i-1).zfill(2) + \"-\" + title + \".md\"\n",
    "    with open(filename, encoding='utf-8', mode='w') as file_writer:\n",
    "        file_writer.write(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- [01 General](01-General.md)\n",
      "- [02 Enabling Tools (Morphology, Diacritization, Grammer, etc.)](02-Enabling-Tools-(Morphology,-Diacritization,-Grammer,-etc.).md)\n",
      "- [03 Text Classification & Mining](03-Text-Classification-&-Mining.md)\n",
      "- [04 Named Entity Recognition](04-Named-Entity-Recognition.md)\n",
      "- [05 Quesion Answering](05-Quesion-Answering.md)\n",
      "- [06 Sentiment Analysis](06-Sentiment-Analysis.md)\n",
      "- [07 Speech](07-Speech.md)\n",
      "- [08 Summarization](08-Summarization.md)\n",
      "- [09 Conversational AI (Chatbots & Dialogue systems)](09-Conversational-AI-(Chatbots-&-Dialogue-systems).md)\n",
      "- [10 Word Sense Disambiguation (WSD)](10-Word-Sense-Disambiguation-(WSD).md)\n",
      "- [11 Dialects](11-Dialects.md)\n",
      "- [12 Plagiarism Detection Systems](12-Plagiarism-Detection-Systems.md)\n",
      "- [13 Machine Translation](13-Machine-Translation.md)\n",
      "- [14 Handwriting Recognition & OCR](14-Handwriting-Recognition-&-OCR.md)\n",
      "- [15 Offensive Language Detection](15-Offensive-Language-Detection.md)\n",
      "- [16 Fake news and Spam](16-Fake-news-and-Spam.md)\n",
      "- [17 Ontology and Resources](17-Ontology-and-Resources.md)\n",
      "- [18 Information Retrieval](18-Information-Retrieval.md)\n",
      "- [19 Opinion Mining](19-Opinion-Mining.md)\n",
      "- [20 Knowledge Graph](20-Knowledge-Graph.md)\n",
      "- [21 Query Expansion](21-Query-Expansion.md)\n",
      "- [22 Religious Text](22-Religious-Text.md)\n",
      "- [23 Others (Steganography, Transfer Learning, Deep learning, etc.)](23-Others-(Steganography,-Transfer-Learning,-Deep-learning,-etc.).md)\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, len(parts)):\n",
    "    part = parts[i]\n",
    "    title = parts[i].split('\\n')[0].strip().replace(' ', '-')\n",
    "    title_with_num = str(i-1).zfill(2) + \"-\" + title\n",
    "    filename = title_with_num + \".md\"\n",
    "    title_with_num_without_spaces = title_with_num.replace('-', ' ')\n",
    "    page_link = f\"- [{title_with_num_without_spaces}]({filename})\"\n",
    "    print(page_link)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da20024804fad5350fda431ea2db37db985e4ababe34a9d1242fe2d15e5370f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
